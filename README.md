# Twitter Authorship Attribution using Machine Learning

## ğŸ¯ Overview
Machine Learning system for identifying tweet authors with 91% accuracy using advanced NLP techniques and ensemble methods.

## ğŸ“Š Performance

| Model | Bag of Words | Embeddings |
|-------|-------------|------------|
| KNN | 67.8% | 76.3% |
| Neural Network | 71.2% | 85.4% |
| **Gradient Boosting** | 83.6% | **91.0%** â­ |
| Random Forest | 65.3% | 77.2% |
| Bagging | 68.1% | 79.5% |

## ğŸš€ Quick Start
```bash
# Clone and setup
git clone https://github.com/asad-waraich/twitter-authorship-attribution.git
cd twitter-authorship-attribution
pip install -r requirements.txt

# Train all models
python scripts/train_all_models.py

# Make predictions
python scripts/predict.py --text "Your tweet text here"
```

## ğŸ“ Dataset
- 5 Twitter accounts (1000 tweets each)
- Authors: @timesofindia, @GordonRamsay, @sonamakapoor, @cnni, @wizkhalifa
- Collected using snscrape (2022)

**Note**: Twitter API changes post-2023 may affect data collection scripts.

## ğŸ› ï¸ Technical Implementation

### Feature Extraction
1. **Bag of Words**: Vocabulary-based with Laplace smoothing
2. **Sentence Embeddings**: 384-dimensional vectors (all-MiniLM-L6-v2)

### Models
- K-Nearest Neighbors (optimized k=1)
- Neural Networks (500x300 architecture)
- Gradient Boosting (100 estimators)
- Random Forest (1000 trees)
- Bagging with Logistic Regression

### Evaluation
- 5-fold cross-validation
- 80/20 train-test split
- Stratified sampling
## ğŸ“Š Results & Visualizations

### Model Performance Comparison

Our experiments show that embeddings significantly outperform traditional Bag-of-Words features:

<p align="center">
  <img src="images/bow_loss_plot.png" alt="BoW Loss Plot" width="45%">
  <img src="images/embeddings_loss_plot.png" alt="Embeddings Loss Plot" width="45%">
</p>


*Left: BoW features (58% accuracy) | Right: Sentence embeddings (83% accuracy)*

### Best Model Results

Using k=1 with sentence embeddings achieved our best performance:

![Best Model Results](images/best_confusion_matrix.png)

**Key Metrics:**
- **Accuracy: 83.06%** 
- Precision: 0.83 (weighted avg)
- Recall: 0.83 (weighted avg)
- F1-Score: 0.83 (weighted avg)

### Performance Improvement Analysis

| Feature Type | Best Accuracy | Optimal k |
|-------------|--------------|-----------|
| Bag-of-Words | 57.76% | k=1 |
| Sentence Embeddings | 83.06% | k=1 |
| **Improvement** | **+25.3%** | - |

## ğŸ”¬ Key Findings
- Embeddings outperform BoW by 10-15% across all models
- Gradient Boosting captures non-linear patterns most effectively
- Performance degrades with 150+ authors (research indicates ~60% accuracy)

## ğŸ“ Applications
- Plagiarism detection
- Digital forensics
- Security & intelligence
- Copyright verification
- Bot detection

## ğŸš§ Future Work
- BERT-based transformers
- Real-time API deployment
- Cross-platform analysis
- Stylometric features
- Active learning pipeline

## ğŸ“„ License
MIT

## ğŸ¤ Contributors
- Asad Ullah Waraich
